{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA  Submission\n",
    "\n",
    "**Claudia Perez Ruisanchez:**\n",
    "\n",
    "**Pneumonia Assistant Classifier:**\n",
    "\n",
    "## Algorithm Description\n",
    "\n",
    "### 1. General Information\n",
    "\n",
    "**Intended Use Statement:**\n",
    "\n",
    "For assisting the radiologist into Pneumonia detection on chest x-rays.\n",
    "\n",
    "**Indications for Use:**\n",
    "\n",
    "* Use in chest x-rays screenings studies\n",
    "* Use in women and men with ages between 10 and 78 years.\n",
    "\n",
    "**Device Limitations:**\n",
    "\n",
    "* Slow performance without GPU\n",
    "* The algorithm is not tested for patients with previous history of Pneumonia.\n",
    "\n",
    "**Clinical Impact of Performance:**\n",
    "\n",
    "Since the algorithm is designed for screening studies we set our threshold in function of maximizing the recall. This is due to the  FP doesnâ€™t have a bit impact on a patient.\n",
    "\n",
    "### 2. Algorithm Design and Function\n",
    "\n",
    "![](flowchart.png)\n",
    "\n",
    "\n",
    "**DICOM Checking Steps:**\n",
    "\n",
    "We create a function that reads in a .dcm file, checks the important fields for our device such as:\n",
    "* check if the image type is 'DX'\n",
    "* check if the body part is 'CHEST'\n",
    "* check if the image position is 'AP' or 'PA'\n",
    "\n",
    "and returns a numpy array with the imaging data its mean and its standard deviation is all the conditions above holds.\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "\n",
    "We standarize  the image and after  we resize the image.\n",
    "\n",
    "**CNN Architecture:**\n",
    "\n",
    "We use the VGG16 CNN with all its layers freezed with the exception of the last convolutional layers on which we did fine tunning with loss='binary_crossentropy', optimizer='adam' and metrics=['binary_accuracy']. We also ad a flatten layer and the output dense layer.\n",
    "\n",
    "![](loss.png)\n",
    "\n",
    "\n",
    "### 3. Algorithm Training\n",
    "\n",
    "**Parameters:**\n",
    "* Types of augmentation used during training\n",
    "          horizontal_flip = True,\n",
    "          height_shift_range= 0.1,\n",
    "          width_shift_range=0.1,\n",
    "          rotation_range=20,\n",
    "          shear_range = 0.1,\n",
    "          zoom_range=0.1\n",
    "* Batch size= 64\n",
    "* Optimizer Adam with learning rate 1e-4\n",
    "* Layers of pre-existing architecture that were frozen\n",
    "\n",
    "        input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
    "        block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
    "        block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
    "        block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0        \n",
    "        block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
    "        block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
    "        block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
    "        block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
    "        block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "        block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "        block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
    "        block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
    "        block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "        block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "        block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
    "        block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "        block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808\n",
    "\n",
    "* Layers of pre-existing architecture that were fine-tuned\n",
    "\n",
    "        block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "        block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0    \n",
    "* Layers added to pre-existing architecture\n",
    "\n",
    "         Flatten()\n",
    "         Dense(1, activation='sigmoid')\n",
    "\n",
    "\n",
    "![](pr.png)\n",
    "\n",
    "**Final Threshold and Explanation:**\n",
    "\n",
    "We decide to use a threshold of 0.39 since was the value obtained for a value of recall of 0.7. We want to have a high recall even penalizing the precision since our algorithm is developed for screening studies and we want to take into account the false negatives.\n",
    "\n",
    "### 4. Databases\n",
    "\n",
    "**Description of Training Dataset:**\n",
    "\n",
    " We have 2290 rows in our training dataset with 27 features. The pneumonia_class is balanced with 50 percent of the data of patients with pneumonia. The gender in slightly imbalanced as we can see as follows, with more males than females:\n",
    "\n",
    " ![](gender.png)\n",
    "\n",
    " The distribution of the ages is as follows with more cases between 10 and 78 years:\n",
    "\n",
    " ![](age.png)\n",
    "\n",
    "**Description of Validation Dataset:**\n",
    "\n",
    "We have 1430 rows in our training dataset with 27 features. The pneumonia_class is imbalanced with 80 percent of the data of patients with pneumonia. The gender in slightly imbalanced as we can see as follows, with more males than females:\n",
    "\n",
    "![](val_gender.png)\n",
    "\n",
    "The distribution of the ages is as follows with more cases between 10 and 78 years:\n",
    "\n",
    "![](val_age.png)\n",
    "\n",
    "### 5. Ground Truth\n",
    "\n",
    " We used the NIH Chest X-ray Dataset, this dataset is highly imbalanced in relation with the patients with pneumonia. NLP-derived labels from the NIH are sub-optimal since they are more general than only the case of Pneumonia, one patient can have more than one disease similar to Pneumonia and many of the with more prevalence in the dataset than Pneumonia. This could impact the algorithm clinical performance.\n",
    "\n",
    "\n",
    "### 6. FDA Validation Plan\n",
    "\n",
    "**Patient Population Description for FDA Validation Dataset:**\n",
    "\n",
    " We want to make sure that the population used for the dataset are women and men with ages between 10 and 78 years with no history of previous Pneumonia disease. We also want an image type of \"DX\" and the only body part examined is the chest\n",
    " imaging modality, body parts examined, age range, gender distribution, prevalence of pneumonia (and other diseases)\n",
    "\n",
    "\n",
    "**Ground Truth Acquisition Methodology:**\n",
    "\n",
    "As the Ground Truth we will use the silver standard approach of using several radiologists since identifying Pneumonia is difficult for radiologists.\n",
    "\n",
    "**Algorithm Performance Standard:**\n",
    "\n",
    "The performance Standard that we will use is the recall since our algorithm is used for screening studies. We want to achieve a recall of more than 0.7. The F1 score of our algorithm was 0.417, this score is above the average of radiologists 0.387 [see this reference](https://arxiv.org/pdf/1711.05225.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
